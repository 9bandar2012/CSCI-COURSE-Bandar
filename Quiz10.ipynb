{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f3103c-81d5-4139-a151-91d986d34ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Dict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150f403b-9d52-4cc2-a1be-b12852e943f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.08779253009842213\n",
      "Linear Regression R²: -0.004388350292662713\n",
      "Linear Regression MSE with one dimension: 0.08779253009842213\n",
      "Linear Regression R² with one dimension: -0.004388350292662713\n",
      "KNN without Normalization: 0.8935483870967742\n",
      "KNN without Normalization for one dimension reduction: 0.896774193548387\n",
      "KNN with Normalization: 0.9032258064516129\n",
      "KNN with Normalization for one dimension reduction: 0.9\n",
      "Logistic Regression without Normalization: 0.9032258064516129\n",
      "Logistic Regression without Normalization for one dimension reduction: 0.9032258064516129\n",
      "Logistic Regression with Normalization: 0.896774193548387\n",
      "Logistic Regression with Normalization for one dimension reduction: 0.9032258064516129\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Credit_card.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "\n",
    "if 'Annual_income' in processed_data.columns and 'label' in processed_data.columns:\n",
    "    X = processed_data[['Annual_income']]  # Feature matrix\n",
    "    y = processed_data['label']  # Target variable\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "\n",
    "    pipe = [('pca', PCA(n_components=1)), ('m', LinearRegression())]\n",
    "    model2 = Pipeline(steps=pipe)\n",
    "\n",
    "    \n",
    "    model2.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    y_pred2 = model2.predict(X_test)\n",
    "\n",
    "        \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "    print(f\"Linear Regression R²: {r2}\")\n",
    "    # model evaluation with one dimension data\n",
    "    mse2 = mean_squared_error(y_test, y_pred2)\n",
    "    r2_x = r2_score(y_test, y_pred2)\n",
    "    print(f\"Linear Regression MSE with one dimension: {mse2}\")\n",
    "    print(f\"Linear Regression R² with one dimension: {r2_x}\")\n",
    "else:\n",
    "    print(\"Required columns are missing in the processed data.\")\n",
    "\n",
    "def evaluate_models(X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluates Linear Regression, KNN, and Logistic Regression models with and without normalization.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    performances: Dict[str, float] = {}\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=8)\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    \n",
    "    pipe1 = [('pca', PCA(n_components=1)), ('m', KNeighborsClassifier(n_neighbors=8))]\n",
    "    \n",
    "    \n",
    "    pipe2 = [('pca', PCA(n_components=1)), ('m', LogisticRegression(max_iter=1000))]\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    performances['KNN without Normalization'] = knn.score(X_test, y_test)\n",
    "    \n",
    "    model3 = Pipeline(steps = pipe1)\n",
    "    model3.fit(X_train, y_train)\n",
    "    \n",
    "    performances['KNN without Normalization for one dimension reduction'] = model3.score(X_test, y_test)\n",
    "    \n",
    "    knn.fit(X_train_normalized, y_train)\n",
    "    performances['KNN with Normalization'] = knn.score(X_test_normalized, y_test)\n",
    "    \n",
    "    model4 = Pipeline(steps = pipe1)\n",
    "    model4.fit(X_train_normalized, y_train)\n",
    "    performances['KNN with Normalization for one dimension reduction'] = model4.score(X_test_normalized, y_test)\n",
    "\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    performances['Logistic Regression without Normalization'] = log_reg.score(X_test, y_test)\n",
    "    \n",
    "    model5 = Pipeline(steps = pipe2)\n",
    "    model5.fit(X_train, y_train)\n",
    "    performances['Logistic Regression without Normalization for one dimension reduction'] = model5.score(X_test, y_test)\n",
    "    \n",
    "    log_reg.fit(X_train_normalized, y_train)\n",
    "    performances['Logistic Regression with Normalization'] = log_reg.score(X_test_normalized, y_test)\n",
    "    #fit logistic regression with normalization for one dimension data\n",
    "    model6 = Pipeline(steps=pipe2)\n",
    "    model6.fit(X_train_normalized, y_train)\n",
    "    performances['Logistic Regression with Normalization for one dimension reduction'] = model6.score(X_test_normalized, y_test)\n",
    "\n",
    "    return performances\n",
    "\n",
    "\n",
    "X = processed_data.drop(['label', 'Annual_income'], axis=1, errors='ignore')\n",
    "y = processed_data['label']\n",
    "\n",
    "\n",
    "performances = evaluate_models(X, y)\n",
    "for model, performance in performances.items():\n",
    "    print(f\"{model}: {performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573c9df-38fa-4c6f-8898-f5fa0c067104",
   "metadata": {},
   "source": [
    "# We can observe from the above input the metrics for linear regression remain unchanged not affecting its performance when one dimension reduction technique is applied. We obseve that KNN without normalization improves from 0.8967 to 0.8935 when one dimension reduction technique is applied. KNN ith normalization reduces from 0.9032 to 0.9. The logistic regression without normalization remains unchanged. Logistic regression without normalization improves from 0.8968 to 0,9032"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
