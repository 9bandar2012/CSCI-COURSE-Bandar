{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5c084d-58ed-4db3-8740-0fc86f575ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17922f4b-5edf-4920-82c9-e9c8e5e0e3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.08779253009842213\n",
      "Linear Regression R²: -0.004388350292662713\n",
      "KNN without Normalization: 0.8935483870967742\n",
      "KNN with Normalization: 0.9032258064516129\n",
      "Logistic Regression without Normalization: 0.9032258064516129\n",
      "Logistic Regression with Normalization: 0.896774193548387\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Credit_card.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "\n",
    "if 'Annual_income' in processed_data.columns and 'label' in processed_data.columns:\n",
    "    X = processed_data[['Annual_income']]  # Feature matrix\n",
    "    y = processed_data['label']  # Target variable\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Linear Regression MSE: {mse}\")\n",
    "    print(f\"Linear Regression R²: {r2}\")\n",
    "else:\n",
    "    print(\"Required columns are missing in the processed data.\")\n",
    "\n",
    "def evaluate_models(X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluates Linear Regression, KNN, and Logistic Regression models with and without normalization.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    performances: Dict[str, float] = {}\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=8)\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    performances['KNN without Normalization'] = knn.score(X_test, y_test)\n",
    "    \n",
    "    knn.fit(X_train_normalized, y_train)\n",
    "    performances['KNN with Normalization'] = knn.score(X_test_normalized, y_test)\n",
    "\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    performances['Logistic Regression without Normalization'] = log_reg.score(X_test, y_test)\n",
    "    \n",
    "    log_reg.fit(X_train_normalized, y_train)\n",
    "    performances['Logistic Regression with Normalization'] = log_reg.score(X_test_normalized, y_test)\n",
    "\n",
    "    return performances\n",
    "\n",
    "\n",
    "X = processed_data.drop(['label', 'Annual_income'], axis=1, errors='ignore')\n",
    "y = processed_data['label']\n",
    "\n",
    "\n",
    "performances = evaluate_models(X, y)\n",
    "for model, performance in performances.items():\n",
    "    print(f\"{model}: {performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22880abb-d1f8-412e-babe-0232df36f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Univariate Linear Regression Analysis\n",
    "# The Univariate Linear Regression analysis using 'Annual_income' as a predictor for the target variable 'label' resulted in an MSE \n",
    "# of 0.08779253009842213 and an R² value of -0.004388350292662491. These metrics indicate that the model is not fitting the data well.\n",
    "# A negative R² value suggests that the model performs worse than a simple horizontal line representing the mean of the target. \n",
    "# This outcome implies that either 'Annual_income' alone does not have a linear relationship with the target or other features are needed \n",
    "# to capture the complexity of the dataset. It points towards exploring more complex models or including more predictors for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da85d55b-3bd8-483f-9314-e30a8e9ec77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: KNN Performance and Optimal K\n",
    "# Normalization improved the KNN model's performance, with accuracy increasing from 0.8935483870967742 without normalization \n",
    "# to 0.9032258064516129 with normalization. This enhancement underscores the significance of feature scaling \n",
    "# for distance-based algorithms like KNN, where normalization ensures all features contribute equally to the distance computation, enhancing model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab2525-a896-40da-b478-de22c71d5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Logistic Regression Performance\n",
    "# For Logistic Regression, the model showed high accuracy both with (0.896774193548387) and without normalization (0.9032258064516129),\n",
    "# with a slight decrease in performance when normalization was applied. \n",
    "# This slight decrease might be due to the model's inherent ability to handle different feature scales, especially when \n",
    "# regularization is applied. However, the high accuracy in both cases suggests that Logistic Regression is well-suited \n",
    "# for this binary classification task, capable of capturing the relationship between features and the target effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc6adb5-6835-41e3-8497-ba60d287d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Impact of Normalization\n",
    "# Normalization had a positive impact on the KNN model's performance but a slightly negative impact on Logistic Regression. \n",
    "# This outcome highlights that the benefits of normalization can vary between models based on their underlying assumptions\n",
    "# and sensitivity to feature scales. While normalization is generally recommended, especially for algorithms like KNN \n",
    "# that are sensitive to the scale of input features, its impact should be evaluated on a case-by-case basis.\n",
    "# For Logistic Regression in this dataset, feature scaling was less critical, possibly due to the model's \n",
    "# characteristics or the data distribution.\n",
    "# Normalization's varying impact on different models emphasizes the importance of understanding model assumptions \n",
    "#and the characteristics of the dataset when preprocessing data. While normalization is beneficial for models sensitive to feature scale, \n",
    "#it might not always enhance performance for all models or datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
